{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Information retrieval\n",
        "\n",
        "## Home Work 6\n",
        "\n",
        "## Evaluating IR Model\n",
        "### Group 1\n",
        "#### Ali Mojahed - 9812762554\n",
        "#### Mehrnoosh Navidimehr - 9822762119\n",
        "#### Minoo Mohaghegh - 9812762270\n",
        "#### Helia Ghahraman - 9822762437\n",
        "\n"
      ],
      "metadata": {
        "id": "cSvKwgMszJPR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Datasets"
      ],
      "metadata": {
        "id": "1dil4_BGzPbE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dlwB5D34ZDX",
        "outputId": "4a3f4ed1-08fe-4210-c5c6-898cd16f1117"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-09 18:42:28--  http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz\n",
            "Resolving ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)... 130.209.240.253\n",
            "Connecting to ir.dcs.gla.ac.uk (ir.dcs.gla.ac.uk)|130.209.240.253|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 775144 (757K) [application/gzip]\n",
            "Saving to: ‘cisi.tar.gz’\n",
            "\n",
            "cisi.tar.gz         100%[===================>] 756.98K  1.29MB/s    in 0.6s    \n",
            "\n",
            "2023-06-09 18:42:29 (1.29 MB/s) - ‘cisi.tar.gz’ saved [775144/775144]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://ir.dcs.gla.ac.uk/resources/test_collections/cisi/cisi.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar xvzf cisi.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agn3RSPJ4p7w",
        "outputId": "e4e6733d-fb8a-4332-962e-cc790acdbfd5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CISI.ALL\n",
            "CISI.BLN\n",
            "CISI.QRY\n",
            "CISI.REL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Required Libraries"
      ],
      "metadata": {
        "id": "4P5eelnIzRt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.stem import PorterStemmer\n"
      ],
      "metadata": {
        "id": "26MzKRsZdbHf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_stopwords = ['ourselves','hers','between','yourself','but','again','there','about','once','during','out','very','having','with',\n",
        "'they','own','an','be','some','for','do','its','yours','such','into','of','most','itself','other','off','is','s',\n",
        "'am','or','who','as','from','him','each','the','themselves','until','below','are','we','these','your','his','through',\n",
        "'don','nor','me','were','her','more','himself','this','down','should','our','their','while','above','both','up','to',\n",
        "'ours','had','she','all','no','when','at','any','before','them','same','and','been','have','in','will','on','does',\n",
        "'yourselves','then','that','because','what','over','why','so','can','did','not','now','under','he','you','herself','has',\n",
        "'just','where','too','only','myself','which','those','i','after','few','whom','t','being','if','theirs','my','against','a',\n",
        "'by','doing','it','how','further','was','here','than']"
      ],
      "metadata": {
        "id": "0f2qafn3d4qp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse Dataset"
      ],
      "metadata": {
        "id": "Be7o5qIezVJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stemming(word):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_word = stemmer.stem(word)\n",
        "    return stemmed_word\n",
        "\n",
        "def clean_doc(liste):\n",
        "    res = []\n",
        "    for word in liste :\n",
        "        new_word = word.lower()\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', new_word)\n",
        "        if new_word != \"\":\n",
        "            res.append(new_word)\n",
        "    return res\n",
        "\n",
        "def clean_doc_stem(liste):\n",
        "    res = []\n",
        "    for word in liste :\n",
        "        new_word = word.lower()\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', new_word)\n",
        "        if new_word != \"\":\n",
        "            new_word_stem = stemming(new_word)\n",
        "            res.append(new_word_stem)\n",
        "    return res"
      ],
      "metadata": {
        "id": "0M0EVZc_dakh"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexation(document):\n",
        "    words = document.split(' ')\n",
        "    words = clean_doc(words)\n",
        "    doc_len = len(words)\n",
        "    word_count = {}\n",
        "    for word in words :\n",
        "        word_count[word] = 0\n",
        "    for word in words :\n",
        "        word_count[word] += 1\n",
        "    \n",
        "    return word_count, doc_len"
      ],
      "metadata": {
        "id": "u-0QqIW4dUlF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def indexation_stem(document):\n",
        "    words = document.split(' ')\n",
        "    words = clean_doc_stem(words)\n",
        "    doc_len = len(words)\n",
        "    word_count = {}\n",
        "    for word in words :\n",
        "        word_count[word] = 0\n",
        "    for word in words :\n",
        "        word_count[word] += 1\n",
        "    \n",
        "    return word_count, doc_len"
      ],
      "metadata": {
        "id": "DXj7jEG4dPz1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadAll(filename, stem) :\n",
        "    word_set = []\n",
        "    cisi_all = {}\n",
        "    id = 0\n",
        "    lines = open(filename).read()\n",
        "    for document in lines.split(\".I \") :\n",
        "        token = \"\"\n",
        "        buffer = \"\"\n",
        "        cross_reference = []\n",
        "        cisi_all[id] = {}\n",
        "        cisi_all[id]['ID'] = id\n",
        "        cisi_all[id]['title'] = \"\"\n",
        "        cisi_all[id][\"text\"] = \"\"\n",
        "        document += \"EndOfDocument\"\n",
        "        for line in document.split(\"\\n\") :\n",
        "            if token == \".T\" and line != \".A\":\n",
        "                cisi_all[id]['title'] = line.replace(\"\\n\", \" \")\n",
        "            elif token == \".W\" and line != \".X\" :\n",
        "                buffer += \" \" + line.replace(\"\\n\", \" \")\n",
        "                continue\n",
        "            elif line == \".X\":\n",
        "                cisi_all[id][\"text\"] = buffer\n",
        "                buffer = \"\"\n",
        "            elif token == \".X\" and line != \"EndOfDocument\":\n",
        "                cross_reference.append(line.split(\"\\t\"))\n",
        "                continue\n",
        "            elif line == \"EndOfDocument\":\n",
        "                cisi_all[id][\"cross_ref\"] = cross_reference\n",
        "                cross_reference = []\n",
        "            token = line\n",
        "        if(stem == True):\n",
        "            cisi_all[id]['word_count'], cisi_all[id]['doc_len'] = indexation_stem(cisi_all[id][\"text\"] + \" \" + cisi_all[id]['title'])\n",
        "        else :\n",
        "            cisi_all[id]['word_count'], cisi_all[id]['doc_len'] = indexation(cisi_all[id][\"text\"] + \" \" + cisi_all[id]['title'])\n",
        "        for word in cisi_all[id]['word_count'].keys():\n",
        "            if word not in word_set :\n",
        "                word_set.append(word)\n",
        "        id += 1\n",
        "    del cisi_all[0]\n",
        "    return cisi_all"
      ],
      "metadata": {
        "id": "BODUxbDU4t-8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = loadAll(\"CISI.ALL\", False)"
      ],
      "metadata": {
        "id": "FWqRJpd8dA4D"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents"
      ],
      "metadata": {
        "id": "Rss9ICnwdyp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadQuery(filename, stem) :\n",
        "    cisi_qry = {}\n",
        "    id = 0\n",
        "    lines = open(filename).read()\n",
        "    for document in lines.split(\".I \") :\n",
        "        token = \"\"\n",
        "        buffer = \"\"\n",
        "        cisi_qry[id] = {}\n",
        "        cisi_qry[id]['ID'] = id\n",
        "        cisi_qry[id][\"query\"] = \"\"\n",
        "        cisi_qry[id][\"text\"] = \"\"\n",
        "        document += \"EndOfDocument\"\n",
        "        for line in document.split(\"\\n\") :\n",
        "            if token == \".W\" and line != \"EndOfDocument\" :\n",
        "                buffer += \" \" + line.replace(\"\\n\", \" \")\n",
        "                continue\n",
        "            elif line == \"EndOfDocument\":\n",
        "                cisi_qry[id][\"query\"] = buffer\n",
        "                cisi_qry[id][\"text\"] = buffer\n",
        "                buffer = \"\"\n",
        "                \n",
        "                continue\n",
        "            token = line\n",
        "        if(stem == True):\n",
        "            cisi_qry[id]['query'], cisi_qry[id]['doc_len'] = indexation_stem(cisi_qry[id][\"query\"])\n",
        "        else :\n",
        "            cisi_qry[id]['query'], cisi_qry[id]['doc_len'] = indexation(cisi_qry[id][\"query\"])\n",
        "        id += 1\n",
        "    del cisi_qry[0]\n",
        "    return cisi_qry"
      ],
      "metadata": {
        "id": "UOV5cr97t44E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadRel(filename) : \n",
        "    cisi_rel = {}\n",
        "    lines = open(filename).read()\n",
        "    lines += \"EndOfDocument\"\n",
        "    buffer = 1\n",
        "    list_buffer = []\n",
        "    for line in lines.split(\"\\n\") :\n",
        "        if(line == \"EndOfDocument\"):\n",
        "            cisi_rel[token] = list_buffer\n",
        "            return cisi_rel\n",
        "        else :\n",
        "            token = int((line[0:6]).replace(\" \",\"\"))\n",
        "            if(token == buffer):\n",
        "                list_buffer.append(int((line[7:13]).replace(\" \",\"\")))\n",
        "                buffer = token\n",
        "                continue\n",
        "            else :\n",
        "                cisi_rel[buffer] = list_buffer\n",
        "                list_buffer = []\n",
        "                list_buffer.append(int((line[7:13]).replace(\" \",\"\")))\n",
        "                buffer = token\n",
        "                continue"
      ],
      "metadata": {
        "id": "eHb9MaMPt--G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = loadQuery(\"CISI.QRY\", False)"
      ],
      "metadata": {
        "id": "4dPtpQ9luPUl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "id": "pEAOyiCu6j44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relations = loadRel(\"CISI.REL\")"
      ],
      "metadata": {
        "id": "bAOo1iEkvQoX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess"
      ],
      "metadata": {
        "id": "2bdcrC1VzZB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUfqZsg0ys1f",
        "outputId": "968b21fa-5dd6-4ab3-890d-7a1792c7d1f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, stem=False, remove_stopwords=False):\n",
        "    # Tokenize text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word.lower() for word in tokens]\n",
        "    \n",
        "    if remove_stopwords:\n",
        "      filtered_tokens = [word for word in filtered_tokens if word.lower() not in stop_words]\n",
        "\n",
        "    # Perform stemming if stem=True\n",
        "    if stem:\n",
        "        stemmer = PorterStemmer()\n",
        "        stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
        "        return stemmed_tokens\n",
        "    \n",
        "    return filtered_tokens"
      ],
      "metadata": {
        "id": "OE0NThas3wuj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Posting-List"
      ],
      "metadata": {
        "id": "G0V733rAzbCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_posting_list(documents, stem=False, remove_stopwords=True):\n",
        "    posting_list = {}\n",
        "    \n",
        "    for doc_id, document in documents.items():\n",
        "        text = document['text']\n",
        "        word_count = document['word_count']\n",
        "        \n",
        "        # Preprocess text\n",
        "        tokens = preprocess_text(text, stem, remove_stopwords)\n",
        "        \n",
        "        # Update posting list\n",
        "        for token in tokens:\n",
        "            if token in posting_list:\n",
        "                posting_list[token].append((doc_id, word_count.get(token, 0)))\n",
        "            else:\n",
        "                posting_list[token] = [(doc_id, word_count.get(token, 0))]\n",
        "    \n",
        "    return posting_list"
      ],
      "metadata": {
        "id": "xTAWFZUd310z"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Information Retreival"
      ],
      "metadata": {
        "id": "9YGvyAbMzc8b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np\n",
        "\n",
        "def retrieve_documents(method, query, documents, stem=False, remove_stopwords=True):\n",
        "    \"\"\"\n",
        "    Retrieve and rank documents based on the specified retrieval method.\n",
        "    \n",
        "    Args:\n",
        "        method (str): Retrieval method string ('lnc.ltc', 'ltc.ltc', 'lnn.lnn', 'lnc.lnc', 'ltn.ltn', 'bnn.bnn').\n",
        "        query (str): Query string.\n",
        "        documents (dict): Dictionary of document IDs and corresponding objects.\n",
        "    \n",
        "    Returns:\n",
        "        list: List of top-ranked document IDs.\n",
        "    \"\"\"\n",
        "    # Tokenize query\n",
        "    query_tokens = preprocess_text(query['text'], stem, remove_stopwords)\n",
        "    # print(query_tokens)\n",
        "    # Create a dictionary to store the document scores\n",
        "    # Create a dictionary to store the document scores\n",
        "    document_scores = {}\n",
        "    \n",
        "    # Create arrays to store the IDF scores and document frequencies\n",
        "    query_idf_scores = np.array([np.log(len(documents) / (sum(1 for doc in documents.values() if term in doc['token_count']) + 1)) for term in query_tokens])\n",
        "    doc_frequencies = np.array([sum(1 for doc in documents.values() if term in doc['token_count']) for term in query_tokens])\n",
        "    \n",
        "    # Calculate document scores based on the retrieval method\n",
        "    for doc_id, doc in documents.items():\n",
        "        term_frequencies = np.array([doc['token_count'].get(term, 0) for term in query_tokens])\n",
        "        if term_frequencies == 0:\n",
        "          term_frequencies = np.ones_like(term_frequencies)\n",
        "\n",
        "        if method == 'lnc.ltc':\n",
        "            max_term_frequencies = np.array([max(doc['token_count'].values(), default=1) for _ in query_tokens])\n",
        "\n",
        "            if max_term_frequencies == 0:\n",
        "              max_term_frequencies = 1\n",
        "\n",
        "            document_weights = (1 + np.log(term_frequencies)) / (1 + np.log(max_term_frequencies))\n",
        "            \n",
        "        elif method == 'ltc.ltc':\n",
        "            document_weights = term_frequencies * query_idf_scores\n",
        "            \n",
        "        elif method == 'lnn.lnn':\n",
        "            document_weights = (1 + np.log(term_frequencies)) * query_idf_scores\n",
        "            \n",
        "        elif method == 'lnc.lnc':\n",
        "            max_term_frequencies = np.array([max(doc['token_count'].values(), default=1) for _ in query_tokens])\n",
        "            if max_term_frequencies == 0:\n",
        "              max_term_frequencies = 1\n",
        "\n",
        "            document_weights = ((1 + np.log(term_frequencies)) / (1 + np.log(max_term_frequencies))) * query_idf_scores\n",
        "            \n",
        "        elif method == 'ltn.ltn':\n",
        "            max_term_frequencies = np.array([max(doc['token_count'].values(), default=1) for _ in query_tokens])\n",
        "            if max_term_frequencies == 0:\n",
        "              max_term_frequencies = 1\n",
        "\n",
        "            document_weights = ((1 + np.log(term_frequencies)) * query_idf_scores) / (1 + np.log(max_term_frequencies))\n",
        "            \n",
        "        elif method == 'bnn.bnn':\n",
        "            document_weights = np.array([1 if term in doc['token_count'] else 0 for term in query_tokens])\n",
        "        \n",
        "        # Calculate the document score based on the weights\n",
        "        document_score = np.sum(document_weights)\n",
        "        document_scores[doc_id] = document_score\n",
        "    \n",
        "    # Rank the documents based on their scores\n",
        "    ranked_documents = sorted(document_scores, key=document_scores.get, reverse=True)\n",
        "    \n",
        "    return ranked_documents\n"
      ],
      "metadata": {
        "id": "_eNcqii1feSH"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluations"
      ],
      "metadata": {
        "id": "z3rSnMmcziSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def precision_at_k(ground_truth, predicted, k):\n",
        "    \"\"\"\n",
        "    Compute precision@k.\n",
        "    \n",
        "    Args:\n",
        "        ground_truth (list): List of ground truth document IDs.\n",
        "        predicted (list): List of predicted document IDs.\n",
        "        k (int): Value of k for precision@k.\n",
        "    \n",
        "    Returns:\n",
        "        float: Precision@k score.\n",
        "    \"\"\"\n",
        "    # print(ground_truth, predicted)\n",
        "    if len(predicted) < k:\n",
        "        k = len(predicted)\n",
        "    \n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    num_correct = len(set(predicted[:k]).intersection(set(ground_truth)))\n",
        "    precision = num_correct / k\n",
        "    \n",
        "    return precision\n",
        "\n",
        "def recall_at_k(ground_truth, predicted, k):\n",
        "    \"\"\"\n",
        "    Compute recall@k.\n",
        "    \n",
        "    Args:\n",
        "        ground_truth (list): List of ground truth document IDs.\n",
        "        predicted (list): List of predicted document IDs.\n",
        "        k (int): Value of k for recall@k.\n",
        "    \n",
        "    Returns:\n",
        "        float: Recall@k score.\n",
        "    \"\"\"\n",
        "    if len(predicted) < k:\n",
        "        k = len(predicted)\n",
        "    \n",
        "    if len(ground_truth) == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    num_correct = len(set(predicted[:k]).intersection(set(ground_truth)))\n",
        "    recall = num_correct / len(ground_truth)\n",
        "    \n",
        "    return recall\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    \"\"\"\n",
        "    Compute F1-score.\n",
        "    \n",
        "    Args:\n",
        "        precision (float): Precision value.\n",
        "        recall (float): Recall value.\n",
        "    \n",
        "    Returns:\n",
        "        float: F1-score.\n",
        "    \"\"\"\n",
        "    if precision == 0 or recall == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    \n",
        "    return f1\n",
        "\n",
        "def average_precision(ground_truth, predicted):\n",
        "    \"\"\"\n",
        "    Compute Average Precision (AP).\n",
        "    \n",
        "    Args:\n",
        "        ground_truth (list): List of ground truth document IDs.\n",
        "        predicted (list): List of predicted document IDs.\n",
        "    \n",
        "    Returns:\n",
        "        float: Average Precision (AP) score.\n",
        "    \"\"\"\n",
        "    num_correct = 0\n",
        "    precision_sum = 0.0\n",
        "    \n",
        "    for i, doc_id in enumerate(predicted):\n",
        "        if doc_id in ground_truth:\n",
        "            num_correct += 1\n",
        "            precision = num_correct / (i + 1)\n",
        "            precision_sum += precision\n",
        "    \n",
        "    if num_correct == 0:\n",
        "        return 0.0\n",
        "    \n",
        "    ap = precision_sum / num_correct\n",
        "    \n",
        "    return ap\n",
        "\n",
        "def mean_average_precision(query_ground_truth, query_predictions):\n",
        "    \"\"\"\n",
        "    Compute Mean Average Precision (MAP).\n",
        "    \n",
        "    Args:\n",
        "        query_ground_truth (dict): Dictionary of query IDs and corresponding ground truth document IDs.\n",
        "        query_predictions (dict): Dictionary of query IDs and corresponding predicted document IDs.\n",
        "    \n",
        "    Returns:\n",
        "        float: Mean Average Precision (MAP) score.\n",
        "    \"\"\"\n",
        "    num_queries = len(query_ground_truth)\n",
        "    map_sum = 0.0\n",
        "    \n",
        "    for query_id, ground_truth in query_ground_truth.items():\n",
        "        predicted = query_predictions.get(query_id, [])\n",
        "        ap = average_precision(ground_truth, predicted)\n",
        "        map_sum += ap\n",
        "    \n",
        "    map_score = map_sum / num_queries\n",
        "    \n",
        "    return map_score\n",
        "\n",
        "def discounted_cumulative_gain(ground_truth, predicted, k):\n",
        "    \"\"\"\n",
        "    Compute Discounted Cumulative Gain (DCG).\n",
        "    \n",
        "    Args:\n",
        "        ground_truth (list): List of ground truth document IDs.\n",
        "        predicted (list): List of predicted document IDs.\n",
        "        k (int): Value of k for DCG.\n",
        "    \n",
        "    Returns:\n",
        "        float: Discounted Cumulative Gain (DCG) score.\n",
        "    \"\"\"\n",
        "    if len(predicted) < k:\n",
        "        k = len(predicted)\n",
        "    \n",
        "    dcg = 0.0\n",
        "    \n",
        "    for i in range(k):\n",
        "        doc_id = predicted[i]\n",
        "        if doc_id in ground_truth:\n",
        "            relevance = 1\n",
        "        else:\n",
        "            relevance = 0\n",
        "        \n",
        "        gain = 2 ** relevance - 1\n",
        "        discount = 1 / (i + 1)\n",
        "        dcg += gain * discount\n",
        "    \n",
        "    return dcg\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bdQRMBqF4mGx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "posting_list = create_posting_list(documents, True)"
      ],
      "metadata": {
        "id": "6zhzI4Qn9Kg1"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "N1zqZeINzlMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_for_each_method(method, stem, allow_stop_words):\n",
        "  query_prediction = {}\n",
        "  query_precisions = []\n",
        "  query_recalls = []\n",
        "  query_f1_scores = []\n",
        "  query_aps = []\n",
        "  query_dcgs = []\n",
        "  # posting_list = create_posting_list(documents, stem, allow_stop_words)\n",
        "  for doc_id, doc in documents.items():\n",
        "    documents[doc_id]['tokens'] = preprocess_text(doc[\"text\"], stem, allow_stop_words)\n",
        "    documents[doc_id]['token_count'] = {key: value for key, value in doc['word_count'].items() if key in documents[doc_id]['tokens']}\n",
        "    # print(documents[doc_id]['token_count'])\n",
        "  \n",
        "  k = 20\n",
        "  for query_id, query in queries.items():\n",
        "    if query_id not in relations.keys():\n",
        "      continue\n",
        "    query_prediction[query_id] = retrieve_documents(method, query, documents, stem, allow_stop_words)\n",
        "    precision = precision_at_k(relations[query_id], query_prediction[query_id], k)\n",
        "    recall = recall_at_k(relations[query_id], query_prediction[query_id], k)\n",
        "    f1 = f1_score(precision, recall)\n",
        "    map_score = mean_average_precision(relations, query_prediction)\n",
        "    dcg = discounted_cumulative_gain(relations[query_id], query_prediction[query_id], k)\n",
        "    \n",
        "    query_precisions.append(precision)\n",
        "    query_recalls.append(recall)\n",
        "    query_f1_scores.append(f1)\n",
        "    query_aps.append(map_score)\n",
        "    query_dcgs.append(dcg)\n",
        "    # print(query_id)\n",
        "\n",
        "\n",
        "\n",
        "  overall_precision = sum(query_precisions) / len(query_precisions)\n",
        "  overall_recall = sum(query_recalls) / len(query_recalls)\n",
        "  overall_f1_score = sum(query_f1_scores) / len(query_f1_scores)\n",
        "  overall_map = sum(query_aps) / len(query_aps)\n",
        "  overall_dcg = sum(query_dcgs) / len(query_dcgs)\n",
        "\n",
        "  print(f\"Method: {method}, stem {stem}, stopwords {allow_stop_words}\")\n",
        "  print(f'Overall Precision: {overall_precision}')\n",
        "  print(f'Overall Recall: {overall_recall}')\n",
        "  print(f'Overall F1-score: {overall_f1_score}')\n",
        "  print(f'Overall MAP: {overall_map}')\n",
        "  print(f'Overall DCG: {overall_dcg}')\n",
        "\n",
        "  return overall_precision, overall_recall, overall_f1_score, overall_map, overall_dcg\n"
      ],
      "metadata": {
        "id": "f7SMW9Oo475E"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report"
      ],
      "metadata": {
        "id": "13YZZ4fSzql1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "import itertools\n",
        "# Define the list of methods, stopwords, and stemming options\n",
        "methods = [ 'lnc.ltc', 'ltc.ltc', 'lnn.lnn', 'lnc.lnc', 'ltn.ltn', 'bnn.bnn']\n",
        "bool_comb = [(True, False), (False, True), (False, False), (True, True)]\n",
        "stemming_options = [True, False]\n",
        "\n",
        "# Define the list of evaluation metrics\n",
        "metrics = ['Precision', 'Recall', 'F1-score', 'MAP', 'DCG']\n",
        "\n",
        "# Create an empty list to store the table data\n",
        "table_data = []\n",
        "\n",
        "# Perform the experiment for each method, stopwords option, and stemming option\n",
        "# for method, allow_stopwords, stemming in zip(methods, stopwords_options, stemming_options):\n",
        "for method, bools in itertools.product(methods, bool_comb):\n",
        "    allow_stopwords, stemming = bools\n",
        "    # # Perform the retrieval and evaluation\n",
        "    # top_documents = retrieve_documents(method, query, documents, stemming, stopwords)\n",
        "    # precision = precision_at_k(ground_truth, top_documents, k)\n",
        "    # recall = recall_at_k(ground_truth, top_documents, k)\n",
        "    # f1 = f1_score(precision, recall)\n",
        "    # map_score = mean_average_precision(query_ground_truth, query_predictions)\n",
        "    # dcg = discounted_cumulative_gain(ground_truth, top_documents, k)\n",
        "    print(method, allow_stopwords, stemming)\n",
        "    precision, recall, f1, map_score, dcg = compute_for_each_method(method, stemming, allow_stopwords)\n",
        "    \n",
        "    # Append the results to the table data\n",
        "    table_data.append([method, allow_stopwords, stemming, precision, recall, f1, map_score, dcg])\n",
        "\n",
        "# Define the headers for the table\n",
        "headers = ['Method', 'Stopwords', 'Stemming', 'Precision', 'Recall', 'F1-score', 'MAP', 'DCG']\n",
        "\n",
        "# Print the table\n",
        "print(tabulate(table_data, headers=headers, tablefmt='pipe'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_OuQBWKC3z8",
        "outputId": "a4da91e9-de8a-4db4-ac3e-57ce9b87dc75"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lnc.ltc True False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-ffde8b210369>:33: RuntimeWarning: divide by zero encountered in log\n",
            "  document_weights = (1 + np.log(term_frequencies)) / (1 + np.log(max_term_frequencies))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: lnc.ltc, stem False, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.ltc False True\n",
            "Method: lnc.ltc, stem True, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.ltc False False\n",
            "Method: lnc.ltc, stem False, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.ltc True True\n",
            "Method: lnc.ltc, stem True, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "ltc.ltc True False\n",
            "Method: ltc.ltc, stem False, stopwords True\n",
            "Overall Precision: 0.2078947368421053\n",
            "Overall Recall: 0.1435442175545432\n",
            "Overall F1-score: 0.13954604188506534\n",
            "Overall MAP: 0.07872004295371188\n",
            "Overall DCG: 0.991267466442633\n",
            "ltc.ltc False True\n",
            "Method: ltc.ltc, stem True, stopwords False\n",
            "Overall Precision: 0.1032894736842105\n",
            "Overall Recall: 0.05483177643191417\n",
            "Overall F1-score: 0.06171963937763379\n",
            "Overall MAP: 0.036111945879769645\n",
            "Overall DCG: 0.4292394909894299\n",
            "ltc.ltc False False\n",
            "Method: ltc.ltc, stem False, stopwords False\n",
            "Overall Precision: 0.17500000000000007\n",
            "Overall Recall: 0.11667220449914555\n",
            "Overall F1-score: 0.11423926993924993\n",
            "Overall MAP: 0.06764220799819842\n",
            "Overall DCG: 0.7890576917040381\n",
            "ltc.ltc True True\n",
            "Method: ltc.ltc, stem True, stopwords True\n",
            "Overall Precision: 0.12631578947368424\n",
            "Overall Recall: 0.06544867172467149\n",
            "Overall F1-score: 0.07538079999988322\n",
            "Overall MAP: 0.041568382560524114\n",
            "Overall DCG: 0.5337743430867109\n",
            "lnn.lnn True False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-ffde8b210369>:39: RuntimeWarning: divide by zero encountered in log\n",
            "  document_weights = (1 + np.log(term_frequencies)) * query_idf_scores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: lnn.lnn, stem False, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnn.lnn False True\n",
            "Method: lnn.lnn, stem True, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnn.lnn False False\n",
            "Method: lnn.lnn, stem False, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnn.lnn True True\n",
            "Method: lnn.lnn, stem True, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.lnc True False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-ffde8b210369>:43: RuntimeWarning: divide by zero encountered in log\n",
            "  document_weights = ((1 + np.log(term_frequencies)) / (1 + np.log(max_term_frequencies))) * query_idf_scores\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: lnc.lnc, stem False, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.lnc False True\n",
            "Method: lnc.lnc, stem True, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.lnc False False\n",
            "Method: lnc.lnc, stem False, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "lnc.lnc True True\n",
            "Method: lnc.lnc, stem True, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "ltn.ltn True False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-82-ffde8b210369>:47: RuntimeWarning: divide by zero encountered in log\n",
            "  document_weights = ((1 + np.log(term_frequencies)) * query_idf_scores) / (1 + np.log(max_term_frequencies))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method: ltn.ltn, stem False, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "ltn.ltn False True\n",
            "Method: ltn.ltn, stem True, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "ltn.ltn False False\n",
            "Method: ltn.ltn, stem False, stopwords False\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "ltn.ltn True True\n",
            "Method: ltn.ltn, stem True, stopwords True\n",
            "Overall Precision: 0.0388157894736842\n",
            "Overall Recall: 0.01723530105486803\n",
            "Overall F1-score: 0.021951178388988572\n",
            "Overall MAP: 0.022012196702679666\n",
            "Overall DCG: 0.13538945811941572\n",
            "bnn.bnn True False\n",
            "Method: bnn.bnn, stem False, stopwords True\n",
            "Overall Precision: 0.16973684210526316\n",
            "Overall Recall: 0.11869435424306778\n",
            "Overall F1-score: 0.11170660705041667\n",
            "Overall MAP: 0.06391424062884114\n",
            "Overall DCG: 0.7584410479351004\n",
            "bnn.bnn False True\n",
            "Method: bnn.bnn, stem True, stopwords False\n",
            "Overall Precision: 0.08684210526315787\n",
            "Overall Recall: 0.04305344574142147\n",
            "Overall F1-score: 0.050207058790573245\n",
            "Overall MAP: 0.031226743835850994\n",
            "Overall DCG: 0.3066183774922775\n",
            "bnn.bnn False False\n",
            "Method: bnn.bnn, stem False, stopwords False\n",
            "Overall Precision: 0.13815789473684217\n",
            "Overall Recall: 0.07772924879590244\n",
            "Overall F1-score: 0.0869619002177914\n",
            "Overall MAP: 0.04505183700993651\n",
            "Overall DCG: 0.5505326822323113\n",
            "bnn.bnn True True\n",
            "Method: bnn.bnn, stem True, stopwords True\n",
            "Overall Precision: 0.11052631578947364\n",
            "Overall Recall: 0.061924212765960364\n",
            "Overall F1-score: 0.06792182736585926\n",
            "Overall MAP: 0.03933824908489083\n",
            "Overall DCG: 0.4511360020653038\n",
            "| Method   | Stopwords   | Stemming   |   Precision |    Recall |   F1-score |       MAP |      DCG |\n",
            "|:---------|:------------|:-----------|------------:|----------:|-----------:|----------:|---------:|\n",
            "| lnc.ltc  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltc.ltc  | True        | False      |   0.207895  | 0.143544  |  0.139546  | 0.07872   | 0.991267 |\n",
            "| ltc.ltc  | False       | True       |   0.103289  | 0.0548318 |  0.0617196 | 0.0361119 | 0.429239 |\n",
            "| ltc.ltc  | False       | False      |   0.175     | 0.116672  |  0.114239  | 0.0676422 | 0.789058 |\n",
            "| ltc.ltc  | True        | True       |   0.126316  | 0.0654487 |  0.0753808 | 0.0415684 | 0.533774 |\n",
            "| lnn.lnn  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| bnn.bnn  | True        | False      |   0.169737  | 0.118694  |  0.111707  | 0.0639142 | 0.758441 |\n",
            "| bnn.bnn  | False       | True       |   0.0868421 | 0.0430534 |  0.0502071 | 0.0312267 | 0.306618 |\n",
            "| bnn.bnn  | False       | False      |   0.138158  | 0.0777292 |  0.0869619 | 0.0450518 | 0.550533 |\n",
            "| bnn.bnn  | True        | True       |   0.110526  | 0.0619242 |  0.0679218 | 0.0393382 | 0.451136 |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tabulate(table_data, headers=headers, tablefmt='pipe'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vSOFdtAztbc",
        "outputId": "1f12e94e-0d9e-4087-c8e0-494f8be7263c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Method   | Stopwords   | Stemming   |   Precision |    Recall |   F1-score |       MAP |      DCG |\n",
            "|:---------|:------------|:-----------|------------:|----------:|-----------:|----------:|---------:|\n",
            "| lnc.ltc  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.ltc  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltc.ltc  | True        | False      |   0.207895  | 0.143544  |  0.139546  | 0.07872   | 0.991267 |\n",
            "| ltc.ltc  | False       | True       |   0.103289  | 0.0548318 |  0.0617196 | 0.0361119 | 0.429239 |\n",
            "| ltc.ltc  | False       | False      |   0.175     | 0.116672  |  0.114239  | 0.0676422 | 0.789058 |\n",
            "| ltc.ltc  | True        | True       |   0.126316  | 0.0654487 |  0.0753808 | 0.0415684 | 0.533774 |\n",
            "| lnn.lnn  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnn.lnn  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| lnc.lnc  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | True        | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | False       | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | False       | False      |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| ltn.ltn  | True        | True       |   0.0388158 | 0.0172353 |  0.0219512 | 0.0220122 | 0.135389 |\n",
            "| bnn.bnn  | True        | False      |   0.169737  | 0.118694  |  0.111707  | 0.0639142 | 0.758441 |\n",
            "| bnn.bnn  | False       | True       |   0.0868421 | 0.0430534 |  0.0502071 | 0.0312267 | 0.306618 |\n",
            "| bnn.bnn  | False       | False      |   0.138158  | 0.0777292 |  0.0869619 | 0.0450518 | 0.550533 |\n",
            "| bnn.bnn  | True        | True       |   0.110526  | 0.0619242 |  0.0679218 | 0.0393382 | 0.451136 |\n"
          ]
        }
      ]
    }
  ]
}